import os
import json
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

BASE_URL = "https://nettruyen.me.uk/trang-chu"
DATA_DIR = "data"
USER_DATA_DIR = "crawler/browser_profile"

os.makedirs(DATA_DIR, exist_ok=True)

def crawl_home():
    with sync_playwright() as p:
        # S·ª≠ d·ª•ng persistent context ƒë·ªÉ gi·ªØ session v√† n√© bot
        context = p.chromium.launch_persistent_context(
            USER_DATA_DIR,
            headless=False,
            args=["--disable-blink-features=AutomationControlled"]
        )
        page = context.new_page()
        print("üåç ƒêang truy c·∫≠p trang ch·ªß NetTruyen...")
        
        page.goto(BASE_URL, wait_until="networkidle", timeout=60000)
        
        # L·∫•y n·ªôi dung HTML sau khi ƒë√£ load xong
        content = page.content()
        soup = BeautifulSoup(content, "lxml")
        
        manga_list = []
        items = soup.select(".item")
        
        for item in items:
            title_el = item.select_one("h3 a")
            img_el = item.select_one("img")
            
            if title_el:
                manga_list.append({
                    "id": title_el['href'].split('/')[-1],
                    "title": title_el.get_text(strip=True),
                    "url": title_el['href'],
                    "thumbnail": img_el['data-original'] if img_el.has_attr('data-original') else img_el['src']
                })

        # L∆∞u v√†o file JSON ƒë·ªÉ Web Flask s·ª≠ d·ª•ng
        with open(os.path.join(DATA_DIR, "manga_list.json"), "w", encoding="utf-8") as f:
            json.dump(manga_list, f, ensure_ascii=False, indent=4)
            
        print(f"‚úÖ ƒê√£ l∆∞u {len(manga_list)} truy·ªán v√†o data/manga_list.json")
        context.close()

if __name__ == "__main__":
    crawl_home()